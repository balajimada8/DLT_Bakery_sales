{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9a626959-61c8-4bba-84d2-2a4ecab1f7ec",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# DLT pipeline\n",
    "\n",
    "This Delta Live Tables (DLT) definition is executed using a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9198e987-5606-403d-9f6d-8f14e6a4017f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dlt\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.functions import lit, col, to_date, trim, lower\n",
    "\n",
    "# Bronze Layer\n",
    "@dlt.table(\n",
    "    comment=\"Raw Bakery Sales data ingested from Parquet\",\n",
    "    name=\"bronze.bakery_sales_raw\"\n",
    ")\n",
    "\n",
    "def bakery_sales_raw():\n",
    "    file_path = \"/FileStore/tables/parq_bakery_sales\"\n",
    "    return spark.read.parquet(file_path)\n",
    "\n",
    "@dlt.table(\n",
    "    comment=\"Raw Bakery Prices data ingested from Delta Table\",\n",
    "    name=\"bronze.bakery_price_raw\"\n",
    ")\n",
    "\n",
    "def bakery_price_raw():\n",
    "    delta_path = \"/FileStore/tables/delta_bakery_price\"\n",
    "    return spark.read.format(\"delta\").load(delta_path)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3fc19dba-61fd-4a89-8f8c-24fee63bfb14",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Silver Layer - Cleaned with expectations\n",
    "# -------------------------\n",
    "\n",
    "@dlt.table(\n",
    "    comment=\"Silver layer for validated Bakery Sales\",\n",
    "    name=\"silver.silver_sales\"\n",
    "    )\n",
    "@dlt.expect_or_drop(\"valid_price\", \"total IS NOT NULL AND total > 0\")\n",
    "@dlt.expect_or_drop(\"valid_date\", \"datetime IS NOT NULL\")\n",
    "def silver_sales():\n",
    "    df = dlt.read(\"bakery_sales_raw\")\n",
    "    return df.withColumn(\"Date\", to_date(\"datetime\", \"MM/dd/yyyy\"))\n",
    "\n",
    "@dlt.table(\n",
    "    comment=\"Silver layer for validated Bakery Price\",\n",
    "    name=\"silver.silver_price\"\n",
    "    )\n",
    "@dlt.expect_or_drop(\"valid_price\", \"price IS NOT NULL AND price > 0\")\n",
    "def silver_price():\n",
    "    df = dlt.read(\"bakery_price_raw\")\n",
    "    return df\n",
    "\n",
    "# -------------------------\n",
    "# Capture Dropped Rows (Invalids)\n",
    "# -------------------------\n",
    "\n",
    "total_col = col(\"total\").cast(\"double\")\n",
    "@dlt.table(\n",
    "    comment=\"Invalid Bakery Sales rows\",\n",
    "    name=\"invalid_data.invalid_sales\"\n",
    "    )\n",
    "def invalid_sales():\n",
    "    return dlt.read(\"bakery_sales_raw\").filter(\n",
    "    (~col(\"total\").isNotNull()) | (total_col <= 0) | (~col(\"datetime\").isNotNull())\n",
    ")\n",
    "\n",
    "price_col = col(\"price\").cast(\"double\")\n",
    "@dlt.table(\n",
    "    comment=\"Invalid Bakery Price rows\",\n",
    "    name=\"invalid_data.invalid_price\"\n",
    "    )\n",
    "def invalid_price():\n",
    "    return dlt.read(\"bakery_price_raw\").filter(\n",
    "    (~col(\"price\").isNotNull()) | (price_col <= 0)\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Gold Layer - Joined & Aggregated\n",
    "# -------------------------\n",
    "\n",
    "@dlt.table(\n",
    "    comment=\"Join only angbutter sales with price\",\n",
    "    name=\"gold.angbutter_sales\"\n",
    "    )\n",
    "def angbutter_sales():\n",
    "    sales = dlt.read(\"silver.silver_sales\")\n",
    "    prices = dlt.read(\"silver.silver_price\")\n",
    "\n",
    "    # Filter only angbutter column is not null\n",
    "    ang_sales = sales.filter(col(\"angbutter\").isNotNull())\n",
    "\n",
    "    # Get angbutter price\n",
    "    ang_price_df = prices.filter(lower(trim(col(\"Name\"))) == \"angbutter\").select(\"price\")\n",
    "\n",
    "    # Cross join with price\n",
    "    result = (\n",
    "        ang_sales.crossJoin(ang_price_df)\n",
    "        .withColumn(\"price\", col(\"price\").cast(\"int\"))\n",
    "        .withColumn(\"revenue\", col(\"angbutter\") * col(\"price\"))\n",
    "        .select(\"datetime\", \"day_of_week\", \"total\", \"angbutter\", \"price\", \"revenue\")\n",
    "    )\n",
    "\n",
    "    return result"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "dlt_pipeline",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
